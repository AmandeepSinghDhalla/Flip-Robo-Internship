{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: \n",
    "Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "\n",
    "first get the webpage https://www.naukri.com/\n",
    "Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "Then click the search button.\n",
    "Then scrape the data for the first 10 jobs results you get.\n",
    "Finally create a dataframe of the scraped data. Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver1 = webdriver.Chrome(r\"D:\\Downloads\\IDM Downloads\\chromedriver.exe\")\n",
    "url1 = \"https://www.naukri.com/\"\n",
    "driver1.get(url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job1 = driver1.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job1.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_location1 = driver1.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_location1.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button1 = driver1.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_button1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles1 = driver1.find_elements_by_xpath(\"//a[@class = 'title fw500 ellipsis']\")\n",
    "titles1 = []\n",
    "for i in job_titles1:\n",
    "    titles1.append(i.text)\n",
    "#titles1\n",
    "\n",
    "company_name1 = driver1.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company1 = []\n",
    "for i in company_name1:\n",
    "    company1.append(i.text)\n",
    "#company1\n",
    "\n",
    "experience1 = driver1.find_elements_by_xpath(\"//li[@class = 'fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "exp1 = []\n",
    "for i in experience1:\n",
    "    exp1.append(i.text)\n",
    "#exp1\n",
    "\n",
    "job_location1 = driver1.find_elements_by_xpath(\"//li[@class = 'fleft grey-text br2 placeHolderLi location']//span\")\n",
    "location1 = []\n",
    "for i in job_location1:\n",
    "    location1.append(i.text)\n",
    "#location1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring Data Analysts For E commerce Platform |...</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For Data Analyst/ MIS Reporting Analyst...</td>\n",
       "      <td>PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DA - Urgent Opening For Data Analyst BFSI Doma...</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - Informatica MDM</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Assistant Vice President - MIS &amp; Reporting ( B...</td>\n",
       "      <td>INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...</td>\n",
       "      <td>12-18 Yrs</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Hiring Data Analysts For E commerce Platform |...   \n",
       "2                                       Data Analyst   \n",
       "3  Hiring For Data Analyst/ MIS Reporting Analyst...   \n",
       "4  DA - Urgent Opening For Data Analyst BFSI Doma...   \n",
       "5                     Data Analyst - Informatica MDM   \n",
       "6  Assistant Vice President - MIS & Reporting ( B...   \n",
       "7                                       Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                        Company Name Experience Required  \\\n",
       "0                 Inflexion Analytix Private Limited             0-3 Yrs   \n",
       "1                   Allegis Services India Pvt. Ltd.             0-5 Yrs   \n",
       "2                                  Applied Materials            7-10 Yrs   \n",
       "3   PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd             2-4 Yrs   \n",
       "4                     Tata Consultancy Services Ltd.             4-9 Yrs   \n",
       "5                Shell India Markets Private Limited             6-9 Yrs   \n",
       "6  INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...           12-18 Yrs   \n",
       "7                           Myntra Designs Pvt. Ltd.             3-6 Yrs   \n",
       "8                           Myntra Designs Pvt. Ltd.             3-6 Yrs   \n",
       "9                           Myntra Designs Pvt. Ltd.             4-9 Yrs   \n",
       "\n",
       "                                            Location  \n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  \n",
       "1                                Bangalore/Bengaluru  \n",
       "2                                Bangalore/Bengaluru  \n",
       "3                                Bangalore/Bengaluru  \n",
       "4  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...  \n",
       "5                                Bangalore/Bengaluru  \n",
       "6                        Mumbai, Bangalore/Bengaluru  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8                                Bangalore/Bengaluru  \n",
       "9                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs1 = pd.DataFrame()\n",
    "jobs1['Job Title'] = titles1\n",
    "jobs1['Company Name'] = company1\n",
    "jobs1['Experience Required'] = exp1\n",
    "jobs1['Location'] = location1\n",
    "jobs1[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: \n",
    "Write a python program to scrape data for “Data Scientist” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver2 = webdriver.Chrome(r\"D:\\Downloads\\IDM Downloads\\chromedriver.exe\")\n",
    "url2 = \"https://www.naukri.com/\"\n",
    "driver2.get(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job2 = driver2.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job2.send_keys('Data Scientist')\n",
    "search_location2 = driver2.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_location2.send_keys(\"Bangalore\")\n",
    "search_button2 = driver2.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_button2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping for Job Title\n",
    "job_titles2 = driver2.find_elements_by_xpath(\"//a[@class = 'title fw500 ellipsis']\")\n",
    "titles2 = []\n",
    "for i in job_titles2:\n",
    "    titles2.append(i.text)\n",
    "#titles2\n",
    "\n",
    "# Scrapping for Company Name\n",
    "company_name2 = driver2.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company2 = []\n",
    "for i in company_name2:\n",
    "    company2.append(i.text)\n",
    "#company2\n",
    "\n",
    "# Scrapping for Job location\n",
    "job_location2 = driver2.find_elements_by_xpath(\"//li[@class = 'fleft grey-text br2 placeHolderLi location']//span\")\n",
    "location2 = []\n",
    "for i in job_location2:\n",
    "    location2.append(i.text)\n",
    "#location2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping for total job description\n",
    "\n",
    "# Finding the urls for each job\n",
    "job_urls2 = []\n",
    "job_url2 = driver2.find_elements_by_xpath(\"//a[@class = 'title fw500 ellipsis']\")\n",
    "for i in job_url2:\n",
    "    job_urls2.append(i.get_attribute(\"href\"))\n",
    "#job_urls2\n",
    "job_urls2 = job_urls2[:10]\n",
    "\n",
    "desc2 = []\n",
    "from selenium.common.exceptions import NoSuchElementException # To handle no such element exception\n",
    "for i in job_urls2:\n",
    "    driver2.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        job_description2 = driver2.find_element_by_xpath(\"//section[@class = 'job-desc']\")\n",
    "        desc2.append(job_description2.text.replace('\\n',''))\n",
    "    except NoSuchElementException:\n",
    "        desc2.append('-')\n",
    "#desc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Total Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Job descriptionJob Role : Data Scientist/Data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist, Modeling</td>\n",
       "      <td>Nielsen</td>\n",
       "      <td>Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...</td>\n",
       "      <td>Job descriptionWe wont say we can predict the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - IBM Garage</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist - Credit risk</td>\n",
       "      <td>Scienaptic Systems</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job descriptionResponsibilities and duties Foc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Big Data - Data Scientist</td>\n",
       "      <td>Xoriant Solutions Pvt Ltd</td>\n",
       "      <td>Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Intel Technology India Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job descriptionWe are seeking an outstanding L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hiring For DATA Scientist - ON Contract Basis ...</td>\n",
       "      <td>GlobalEdx Learning and Technology Solution Pvt...</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, M...</td>\n",
       "      <td>Job descriptionDear Aspirant,Greetings from Gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist - Chatbot &amp; NLP</td>\n",
       "      <td>Gojek Tech</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job descriptionWhat You Will DoWork with Data ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                    Senior Data Scientist, Modeling   \n",
       "2                        Data Scientist - IBM Garage   \n",
       "3                                     Data Scientist   \n",
       "4                Senior Data Scientist - Credit risk   \n",
       "5                          Big Data - Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                                Lead Data Scientist   \n",
       "8  Hiring For DATA Scientist - ON Contract Basis ...   \n",
       "9              Senior Data Scientist - Chatbot & NLP   \n",
       "\n",
       "                                        Company Name  \\\n",
       "0                 Inflexion Analytix Private Limited   \n",
       "1                                            Nielsen   \n",
       "2                             IBM India Pvt. Limited   \n",
       "3                             IBM India Pvt. Limited   \n",
       "4                                 Scienaptic Systems   \n",
       "5                          Xoriant Solutions Pvt Ltd   \n",
       "6                             IBM India Pvt. Limited   \n",
       "7                     Intel Technology India Pvt Ltd   \n",
       "8  GlobalEdx Learning and Technology Solution Pvt...   \n",
       "9                                         Gojek Tech   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1  Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...   \n",
       "2  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "3  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8  Hyderabad/Secunderabad, Bangalore/Bengaluru, M...   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                   Total Description  \n",
       "0  Job descriptionJob Role : Data Scientist/Data ...  \n",
       "1  Job descriptionWe wont say we can predict the ...  \n",
       "2                                                  -  \n",
       "3                                                  -  \n",
       "4  Job descriptionResponsibilities and duties Foc...  \n",
       "5                                                  -  \n",
       "6                                                  -  \n",
       "7  Job descriptionWe are seeking an outstanding L...  \n",
       "8  Job descriptionDear Aspirant,Greetings from Gl...  \n",
       "9  Job descriptionWhat You Will DoWork with Data ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs2 = pd.DataFrame()\n",
    "jobs2['Job Title'] = titles2\n",
    "jobs2['Company Name'] = company2\n",
    "jobs2['Location'] = location2\n",
    "jobs2 = jobs2.iloc[:10,:]\n",
    "jobs2['Total Description'] = desc2\n",
    "jobs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: \n",
    "In this question you have to scrape data using the filters available on the\n",
    "webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name,\n",
    "experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note- All of the above steps have to be done in code. No step is to be done\n",
    "manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver3 = webdriver.Chrome(r\"D:\\Downloads\\IDM Downloads\\chromedriver.exe\")\n",
    "url3 = \"https://www.naukri.com/\"\n",
    "driver3.get(url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering title and location on webpage.\n",
    "search_job3 = driver3.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job3.send_keys('Data Scientist')\n",
    "search_location3 = driver3.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_location3.send_keys(\"Delhi/NCR\")\n",
    "search_button3 = driver3.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_button3.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enterning the filters required\n",
    "location_filter3 = driver3.find_element_by_xpath(\"//label[@for = 'chk-Delhi / NCR-cityTypeGid-']//i\")\n",
    "location_filter3.click()\n",
    "time.sleep(5)\n",
    "salary_filter3 = driver3.find_element_by_xpath(\"//label[@for = 'chk-3-6 Lakhs-ctcFilter-']//i\")\n",
    "salary_filter3.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping for job titles\n",
    "job_titles3 = driver3.find_elements_by_xpath(\"//a[@class = 'title fw500 ellipsis']\")\n",
    "titles3 = []\n",
    "for i in job_titles3:\n",
    "    titles3.append(i.text)\n",
    "#titles3\n",
    "\n",
    "# Scrapping for company name\n",
    "company_name3 = driver3.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company3 = []\n",
    "for i in company_name3:\n",
    "    company3.append(i.text)\n",
    "#company3\n",
    "\n",
    "# Scrapping for experience required\n",
    "experience3 = driver3.find_elements_by_xpath(\"//li[@class = 'fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "exp3 = []\n",
    "for i in experience3:\n",
    "    exp3.append(i.text)\n",
    "#exp3\n",
    "\n",
    "# Scrapping for job location\n",
    "job_location3 = driver3.find_elements_by_xpath(\"//li[@class = 'fleft grey-text br2 placeHolderLi location']//span\")\n",
    "location3 = []\n",
    "for i in job_location3:\n",
    "    location3.append(i.text)\n",
    "#location3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "      <th>Job Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - High growth VC backed Influen...</td>\n",
       "      <td>Ravgins International Pvt. Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excellent opportunity For Data Scientist</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mobikwik</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>New Delhi, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Noida</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Noida/ B'lore</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Cloudstrats Technologies Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Data Scientist - High growth VC backed Influen...   \n",
       "2           Excellent opportunity For Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4           DATA Scientist – Gurgaon (Exp 3-6 years)   \n",
       "5           DATA Scientist – Gurgaon (Exp 3-6 years)   \n",
       "6                             Data Scientist - Noida   \n",
       "7                     Data Scientist - Noida/ B'lore   \n",
       "8                                     Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Company Name Experience Required  \\\n",
       "0                 Inflexion Analytix Private Limited             0-3 Yrs   \n",
       "1                    Ravgins International Pvt. Ltd.             3-5 Yrs   \n",
       "2              NEC CORPORATION INDIA PRIVATE LIMITED             3-7 Yrs   \n",
       "3                                           Mobikwik             3-5 Yrs   \n",
       "4  CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...             3-6 Yrs   \n",
       "5  CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...             3-6 Yrs   \n",
       "6     Optum Global Solutions (India) Private Limited             3-5 Yrs   \n",
       "7              NEC CORPORATION INDIA PRIVATE LIMITED             3-8 Yrs   \n",
       "8           Cloudstrats Technologies Private Limited             5-8 Yrs   \n",
       "9                             IBM India Pvt. Limited             4-9 Yrs   \n",
       "\n",
       "                                        Job Location  \n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  \n",
       "1  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...  \n",
       "2                         Noida, Bangalore/Bengaluru  \n",
       "3           New Delhi, Gurgaon/Gurugram, Delhi / NCR  \n",
       "4                      Gurgaon/Gurugram, Delhi / NCR  \n",
       "5                      Gurgaon/Gurugram, Delhi / NCR  \n",
       "6                                              Noida  \n",
       "7                         Noida, Bangalore/Bengaluru  \n",
       "8  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...  \n",
       "9  Noida, Hyderabad/Secunderabad, Bangalore/Benga...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs3 = pd.DataFrame()\n",
    "jobs3['Job Title'] = titles3\n",
    "jobs3['Company Name'] = company3\n",
    "jobs3['Experience Required'] = exp3\n",
    "jobs3['Job Location'] = location3\n",
    "jobs3[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: \n",
    "Write a python program to scrape data for first 10 job results for Data scientist\n",
    "Designation in Noida location. You have to scrape company_name, No. of days\n",
    "ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida”\n",
    "in “location” field.\n",
    "3. Then click the search button. You will land up in the below page:\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown page.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note- All of the above steps have to be done in code. No step is to be done\n",
    "manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPLEASE SIGN IN FOR THE WEBSITE IN THE OPEN CHROME DRIVER POP_UP !!!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Opening the chrome driver pop-up \n",
    "driver4 = webdriver.Chrome(r\"D:\\Downloads\\IDM Downloads\\chromedriver.exe\")\n",
    "url4 = \"https://www.glassdoor.co.in/Job/Home/recentActivity.htm\"\n",
    "driver4.get(url4)\n",
    "print(\"\\033[1mPLEASE SIGN IN FOR THE WEBSITE IN THE OPEN CHROME DRIVER POP_UP !!!\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting in the search values\n",
    "# searching job title\n",
    "search_job4 = driver4.find_element_by_id(\"sc.keyword\")\n",
    "search_job4.send_keys('Data Scientist')\n",
    "time.sleep(1)\n",
    "\n",
    "# searching location\n",
    "search_location4 = driver4.find_element_by_id(\"sc.location\")\n",
    "search_location4.clear()\n",
    "time.sleep(1)\n",
    "search_location4.send_keys(\"Noida\")\n",
    "\n",
    "#clicking search button\n",
    "search_button4 = driver4.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "search_button4.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping for Job Titles \n",
    "job_titles4 = driver4.find_elements_by_xpath(\"//a[@class = 'jobLink css-1rd3saf eigr9kq2']//span\")\n",
    "titles4 = []\n",
    "for i in job_titles4:\n",
    "    titles4.append(i.text)\n",
    "#titles4\n",
    "\n",
    "# Scrapping for company name\n",
    "company_name4 = driver4.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']//span\")\n",
    "company4 = []\n",
    "for i in company_name4:\n",
    "    company4.append(i.text)\n",
    "#company4\n",
    "\n",
    "# Scrapping for days of job posting\n",
    "no_of_days4 = driver4.find_elements_by_xpath(\"//div[@data-test = 'job-age']\")\n",
    "days4 = []\n",
    "for i in no_of_days4:\n",
    "    days4.append(i.text)\n",
    "#days4\n",
    "\n",
    "# Scrapping for company rating\n",
    "company_rating4 = driver4.find_elements_by_xpath(\"//div[@class = 'd-flex flex-column css-x75kgh e1rrn5ka3']\")\n",
    "rating4 = []\n",
    "for i in company_rating4:\n",
    "    rating4.append(i.text)\n",
    "#rating4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Company Rating</th>\n",
       "      <th>No. of Days Old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead Analyst- Data Science</td>\n",
       "      <td>Infosys Limited</td>\n",
       "      <td>3.8</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Applied Materials Inc.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>GSK</td>\n",
       "      <td>3.8</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead- Python (Data Science)</td>\n",
       "      <td>Infosys Limited</td>\n",
       "      <td>3.8</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist (BE/ B-tech 4-6 yrs)</td>\n",
       "      <td>CommerceIQ</td>\n",
       "      <td>3.8</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mercedes-Benz Research and Development India P...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analytics part time job/internship at Ban...</td>\n",
       "      <td>CueLearn</td>\n",
       "      <td>3.9</td>\n",
       "      <td>10d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - IBM Garage</td>\n",
       "      <td>IBM</td>\n",
       "      <td>3.9</td>\n",
       "      <td>17d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RAU-Data Scientist</td>\n",
       "      <td>HDFC Bank</td>\n",
       "      <td>3.6</td>\n",
       "      <td>25d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                         Lead Analyst- Data Science   \n",
       "1                                     Data Scientist   \n",
       "2                                     Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4                        Lead- Python (Data Science)   \n",
       "5                Data Scientist (BE/ B-tech 4-6 yrs)   \n",
       "6                                     Data Scientist   \n",
       "7  Data Analytics part time job/internship at Ban...   \n",
       "8                        Data Scientist - IBM Garage   \n",
       "9                                 RAU-Data Scientist   \n",
       "\n",
       "                                        Company Name Company Rating  \\\n",
       "0                                    Infosys Limited            3.8   \n",
       "1                             Applied Materials Inc.            4.0   \n",
       "2                                                GSK            3.8   \n",
       "3                                                IBM            3.9   \n",
       "4                                    Infosys Limited            3.8   \n",
       "5                                         CommerceIQ            3.8   \n",
       "6  Mercedes-Benz Research and Development India P...            4.0   \n",
       "7                                           CueLearn            3.9   \n",
       "8                                                IBM            3.9   \n",
       "9                                          HDFC Bank            3.6   \n",
       "\n",
       "  No. of Days Old  \n",
       "0            30d+  \n",
       "1            30d+  \n",
       "2             24h  \n",
       "3              3d  \n",
       "4            30d+  \n",
       "5                  \n",
       "6              8d  \n",
       "7             10d  \n",
       "8             17d  \n",
       "9             25d  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs4 = pd.DataFrame()\n",
    "jobs4['Job Title'] = titles4\n",
    "jobs4['Company Name'] = company4\n",
    "jobs4['Company Rating'] = rating4\n",
    "jobs4['No. of Days Old'] = days4\n",
    "jobs4[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: \n",
    "Write a python program to scrape the salary data for Data Scientist designation\n",
    "in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min\n",
    "salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page. You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company.\n",
    "6. Store the data in a dataframe.\n",
    "\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the webpage on chrome driver.\n",
    "driver5 = webdriver.Chrome(r\"D:\\Downloads\\IDM Downloads\\chromedriver.exe\")\n",
    "url5 = \"https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "driver5.get(url5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting in the search values\n",
    "# searching job title\n",
    "search_job5 = driver5.find_element_by_id(\"KeywordSearch\")\n",
    "search_job5.send_keys('Data Scientist')\n",
    "time.sleep(1)\n",
    "\n",
    "# searching location\n",
    "search_location5 = driver5.find_element_by_id(\"LocationSearch\")\n",
    "search_location5.clear()\n",
    "time.sleep(1)\n",
    "search_location5.send_keys(\"Noida\")\n",
    "\n",
    "#clicking search button\n",
    "search_button5 = driver5.find_element_by_xpath(\"//button[@class='gd-btn-mkt']\")\n",
    "search_button5.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping for company name\n",
    "company_name5 = driver5.find_elements_by_xpath(\"//p[@class = 'm-0 ']\")\n",
    "company5 = []\n",
    "for i in company_name5:\n",
    "    company5.append(i.text)\n",
    "#company5\n",
    "\n",
    "# Scrapping for maximum and minimum salary\n",
    "salary5 = driver5.find_elements_by_xpath(\"//div[@class = 'common__RangeBarStyle__values d-flex justify-content-between ']\")\n",
    "salaries5 = []\n",
    "for i in salary5:\n",
    "    salaries5.append(i.text)\n",
    "#salaries5 - list with both maximum and minimum salaries.\n",
    "\n",
    "'''indexing to obtain max and min salaries'''\n",
    "min_salary5 = []\n",
    "for i in salaries5:\n",
    "    min_salary5.append(i.split('\\n')[0])\n",
    "#min_salary5\n",
    "\n",
    "max_salary5 = []\n",
    "for i in salaries5:\n",
    "    max_salary5.append(i.split('\\n')[1])\n",
    "#max_salary5\n",
    "\n",
    "# Scrapping for average salary.\n",
    "avg_sal5 = driver5.find_elements_by_xpath(\"//div[@class = 'col-2 d-none d-md-flex flex-row justify-content-end']\")\n",
    "avgsal5 = []\n",
    "for i in avg_sal5:\n",
    "    avgsal5.append(i.text.replace('\\n', ''))\n",
    "#avgsal5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹ 6,11,228/yr</td>\n",
       "      <td>₹343K</td>\n",
       "      <td>₹1,095K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹ 11,46,533/yr</td>\n",
       "      <td>₹577K</td>\n",
       "      <td>₹2,213K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹ 8,97,795/yr</td>\n",
       "      <td>₹586K</td>\n",
       "      <td>₹2,730K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹ 7,38,057/yr</td>\n",
       "      <td>₹355K</td>\n",
       "      <td>₹1,613K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹ 12,39,781/yr</td>\n",
       "      <td>₹450K</td>\n",
       "      <td>₹11,622K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹ 13,36,142/yr</td>\n",
       "      <td>₹1,069K</td>\n",
       "      <td>₹1,520K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹ 8,15,192/yr</td>\n",
       "      <td>₹502K</td>\n",
       "      <td>₹1,465K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>₹ 11,35,221/yr</td>\n",
       "      <td>₹202K</td>\n",
       "      <td>₹1,809K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹ 11,44,243/yr</td>\n",
       "      <td>₹575K</td>\n",
       "      <td>₹1,520K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>₹ 14,13,288/yr</td>\n",
       "      <td>₹1,014K</td>\n",
       "      <td>₹2,149K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company Name  Average Salary Minimum Salary Maximum Salary\n",
       "0  Tata Consultancy Services   ₹ 6,11,228/yr          ₹343K        ₹1,095K\n",
       "1                  Accenture  ₹ 11,46,533/yr          ₹577K        ₹2,213K\n",
       "2                        IBM   ₹ 8,97,795/yr          ₹586K        ₹2,730K\n",
       "3         Ericsson-Worldwide   ₹ 7,38,057/yr          ₹355K        ₹1,613K\n",
       "4                  Delhivery  ₹ 12,39,781/yr          ₹450K       ₹11,622K\n",
       "5         UnitedHealth Group  ₹ 13,36,142/yr        ₹1,069K        ₹1,520K\n",
       "6         Valiance Solutions   ₹ 8,15,192/yr          ₹502K        ₹1,465K\n",
       "7              ZS Associates  ₹ 11,35,221/yr          ₹202K        ₹1,809K\n",
       "8                EXL Service  ₹ 11,44,243/yr          ₹575K        ₹1,520K\n",
       "9     Optum Global Solutions  ₹ 14,13,288/yr        ₹1,014K        ₹2,149K"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs5 = pd.DataFrame()\n",
    "jobs5['Company Name'] = company5\n",
    "jobs5['Average Salary'] = avgsal5\n",
    "jobs5['Minimum Salary'] = min_salary5\n",
    "jobs5['Maximum Salary'] = max_salary5\n",
    "jobs5[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 : \n",
    "Scrape data of first 100 sunglasses listings on flipkart.com. You have to\n",
    "scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it\n",
    "5. Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses.\n",
    "\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the webpage on chrome driver\n",
    "driver6 = webdriver.Chrome(r\"D:\\Downloads\\IDM Downloads\\chromedriver.exe\")\n",
    "url6 = \"https://www.flipkart.com/\"\n",
    "driver6.get(url6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login cross button\n",
    "cross_button6 = driver6.find_element_by_xpath(\"//button[@class = '_2KpZ6l _2doB4z']\")\n",
    "cross_button6.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting in the search values\n",
    "# searching sunglasses\n",
    "search_item6 = driver6.find_element_by_xpath(\"//input[@class = '_3704LK']\")\n",
    "search_item6.send_keys('Sunglasses')\n",
    "time.sleep(1)\n",
    "\n",
    "#clicking search button\n",
    "search_button6 = driver6.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_button6.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of products from first page: 40\n"
     ]
    }
   ],
   "source": [
    "# Scrapping the brand name from first page\n",
    "brand_name6 = driver6.find_elements_by_xpath(\"//div[@class = '_2WkVRV']\")\n",
    "brand6 = []\n",
    "for i in brand_name6:\n",
    "    brand6.append(i.text)\n",
    "#brand6\n",
    "\n",
    "# Scrapping product description from first page\n",
    "product_desc6 = driver6.find_elements_by_xpath(\"//div[@class = '_2B099V']//a[1]\")\n",
    "description6 = []\n",
    "for i in product_desc6:\n",
    "    description6.append(i.text)\n",
    "#description6\n",
    "\n",
    "# Scrapping price from first page\n",
    "price6 = driver6.find_elements_by_xpath(\"//div[@class = '_30jeq3']\")\n",
    "mrp6 = []\n",
    "for i in price6:\n",
    "    mrp6.append(i.text)\n",
    "#mrp6\n",
    "\n",
    "# SCrapping discount from first page\n",
    "discount6 = driver6.find_elements_by_xpath(\"//div[@class = '_3Ay6Sb']\")\n",
    "disc6 = []\n",
    "for i in discount6:\n",
    "    disc6.append(i.text)\n",
    "#disc6\n",
    "\n",
    "print(f\"Total number of products from first page: {len(brand6)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that we have to scrap the total of 100 product for this problem, so we move onto next page and see how many products we have got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List appended. Total Products: 80\n"
     ]
    }
   ],
   "source": [
    "if len(brand6) < 100:\n",
    "    next_button6 = driver6.find_element_by_xpath(\"//a[@class = '_1LKTO3']//span\")\n",
    "    next_button6.click()\n",
    "    time.sleep(2)\n",
    "    brand_name6 = driver6.find_elements_by_xpath(\"//div[@class = '_2WkVRV']\")\n",
    "    product_desc6 = driver6.find_elements_by_xpath(\"//div[@class = '_2B099V']//a[1]\")\n",
    "    price6 = driver6.find_elements_by_xpath(\"//div[@class = '_30jeq3']\")\n",
    "    discount6 = driver6.find_elements_by_xpath(\"//div[@class = '_3Ay6Sb']\")   \n",
    "    for i in brand_name6:\n",
    "        brand6.append(i.text)\n",
    "    for i in product_desc6:\n",
    "        description6.append(i.text)\n",
    "    for i in price6:\n",
    "        mrp6.append(i.text)\n",
    "    for i in discount6:\n",
    "        disc6.append(i.text)\n",
    "    print(f\"List appended. Total Products: {len(brand6)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go again and again until the total number of products are achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List appended. Total Products: 120\n"
     ]
    }
   ],
   "source": [
    "if len(brand6) < 100:\n",
    "    next_button6 = driver6.find_element_by_xpath(\"//a[@class = '_1LKTO3'][2]\")\n",
    "    next_button6.click()\n",
    "    time.sleep(2)\n",
    "    brand_name6 = driver6.find_elements_by_xpath(\"//div[@class = '_2WkVRV']\")\n",
    "    product_desc6 = driver6.find_elements_by_xpath(\"//div[@class = '_2B099V']//a[1]\")\n",
    "    price6 = driver6.find_elements_by_xpath(\"//div[@class = '_30jeq3']\")\n",
    "    discount6 = driver6.find_elements_by_xpath(\"//div[@class = '_3Ay6Sb']\")   \n",
    "    for i in brand_name6:\n",
    "        brand6.append(i.text)\n",
    "    for i in product_desc6:\n",
    "        description6.append(i.text)\n",
    "    for i in price6:\n",
    "        mrp6.append(i.text)\n",
    "    for i in discount6:\n",
    "        disc6.append(i.text)\n",
    "    print(f\"List appended. Total Products: {len(brand6)}\")\n",
    "else:\n",
    "    print(f\"Total products: {len(brand6)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have got total of 120 products, we can now save the complete data into the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Description</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Price after discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Round, Shield Sunglass...</td>\n",
       "      <td>77% off</td>\n",
       "      <td>₹395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (49)</td>\n",
       "      <td>66% off</td>\n",
       "      <td>₹664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>21% off</td>\n",
       "      <td>₹630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>15% off</td>\n",
       "      <td>₹758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>77% off</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>FOSSIL</td>\n",
       "      <td>Others Rectangular Sunglasses (54)</td>\n",
       "      <td>55% off</td>\n",
       "      <td>₹2,625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>88% off</td>\n",
       "      <td>₹279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Mirrored Aviator Sunglasses (58)</td>\n",
       "      <td>73% off</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (58)</td>\n",
       "      <td>66% off</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Gradient, Night Vision, Mirrore...</td>\n",
       "      <td>69% off</td>\n",
       "      <td>₹377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Product                                        Description  \\\n",
       "0           AISLIN  UV Protection, Gradient Round, Shield Sunglass...   \n",
       "1        ROYAL SON         UV Protection Retro Square Sunglasses (49)   \n",
       "2         Fastrack   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "3         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "4   ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)   \n",
       "..             ...                                                ...   \n",
       "95          FOSSIL                 Others Rectangular Sunglasses (54)   \n",
       "96       Elligator                UV Protection Round Sunglasses (54)   \n",
       "97       ROYAL SON                   Mirrored Aviator Sunglasses (58)   \n",
       "98       ROYAL SON         UV Protection Retro Square Sunglasses (58)   \n",
       "99           NuVew  UV Protection, Gradient, Night Vision, Mirrore...   \n",
       "\n",
       "   Discount Price after discount  \n",
       "0   77% off                 ₹395  \n",
       "1   66% off                 ₹664  \n",
       "2   21% off                 ₹630  \n",
       "3   15% off                 ₹758  \n",
       "4   77% off                 ₹499  \n",
       "..      ...                  ...  \n",
       "95  55% off               ₹2,625  \n",
       "96  88% off                 ₹279  \n",
       "97  73% off                 ₹399  \n",
       "98  66% off                 ₹499  \n",
       "99  69% off                 ₹377  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products6 = pd.DataFrame()\n",
    "products6['Product'] = brand6[:100]\n",
    "products6['Description'] = description6[:100]\n",
    "products6['Discount'] = disc6[:100]\n",
    "products6['Price after discount'] = mrp6[:100]\n",
    "products6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7: \n",
    "Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to\n",
    "go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage.\n",
    "As shown in the above page you have to scrape the tick marked attributes.\n",
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver7 = webdriver.Chrome(r\"D:\\Downloads\\IDM Downloads\\chromedriver.exe\")\n",
    "url7 = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\"\n",
    "driver7.get(url7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all the revies using all reviews button\n",
    "all_rev_button = driver7.find_element_by_xpath(\"//div[@class = '_3UAT2v _16PBlm']\")\n",
    "time.sleep(3)\n",
    "all_rev_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping for the ratings from the first webpage.\n",
    "rating7 = []\n",
    "product_rating7 = driver7.find_elements_by_xpath(\"//div[@class = 'col _2wzgFH K0kLPL']//div[@class= 'row'][1]//div[1]\")\n",
    "for i in product_rating7:\n",
    "    rating7.append(i.text)\n",
    "#rating7 - we get a total of 60 values which consist invalid values along the ratings. We will slice the list at the end.\n",
    "\n",
    "# Scrappiing for the review summary\n",
    "product_review7 = driver7.find_elements_by_xpath(\"//p[@class = '_2-N8zT']\")\n",
    "review7 = []\n",
    "for i in product_review7:\n",
    "    review7.append(i.text)\n",
    "#review7\n",
    "\n",
    "# Scrapping for the total full review\n",
    "product_full_review7 = driver7.find_elements_by_xpath(\"//div[@class = 't-ZTKy']\")\n",
    "full_review7 = []\n",
    "for i in product_full_review7:\n",
    "    full_review7.append(i.text.replace('\\n',' ').replace('❤️','').replace('😃', ''))\n",
    "#full_review7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List appended. Lists length: 20\n"
     ]
    }
   ],
   "source": [
    "# Going to the second web page.\n",
    "if len(review7) < 100:\n",
    "    next_button7 = driver7.find_element_by_xpath(\"//a[@class = '_1LKTO3']//span\")\n",
    "    next_button7.click() # clicking the next button\n",
    "    time.sleep(3)\n",
    "    product_rating7 = driver7.find_elements_by_xpath(\"//div[@class = 'col _2wzgFH K0kLPL']//div[@class= 'row'][1]//div[1]\")\n",
    "    product_review7 = driver7.find_elements_by_xpath(\"//p[@class = '_2-N8zT']\")\n",
    "    product_full_review7 = driver7.find_elements_by_xpath(\"//div[@class = 't-ZTKy']\") \n",
    "    for i in product_rating7:\n",
    "        rating7.append(i.text) # appending the list again\n",
    "    for i in product_review7:\n",
    "        review7.append(i.text) # appending the list again\n",
    "    for i in product_full_review7:\n",
    "        full_review7.append(i.text.replace('\\n',' ').replace('❤️','').replace('😃', '')) # appending the list again\n",
    "\n",
    "    print(f\"List appended. Lists length: {len(review7)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List appended. Lists length: 30\n",
      "List appended. Lists length: 40\n",
      "List appended. Lists length: 50\n",
      "List appended. Lists length: 60\n",
      "List appended. Lists length: 70\n",
      "List appended. Lists length: 80\n",
      "List appended. Lists length: 90\n",
      "List appended. Lists length: 100\n",
      "Total reviews: 100\n"
     ]
    }
   ],
   "source": [
    "'''Assigning a while loop to go to next page and scrap data from that page until we have a total of 1000 reviews of the product'''\n",
    "\n",
    "while len(review7) <= 100: # while loop to repeat clicking to go to next page until 100 reviews scrapped\n",
    "    if len(review7) < 100:\n",
    "        next_button7 = driver7.find_element_by_xpath(\"//a[@class = '_1LKTO3'][2]\")\n",
    "        next_button7.click()\n",
    "        time.sleep(3)\n",
    "        product_rating7 = driver7.find_elements_by_xpath(\"//div[@class = 'col _2wzgFH K0kLPL']//div[@class= 'row'][1]//div[1]\")\n",
    "        product_review7 = driver7.find_elements_by_xpath(\"//p[@class = '_2-N8zT']\")\n",
    "        product_full_review7 = driver7.find_elements_by_xpath(\"//div[@class = 't-ZTKy']\")   \n",
    "        for i in product_rating7:\n",
    "            rating7.append(i.text)\n",
    "        for i in product_review7:\n",
    "            review7.append(i.text)\n",
    "        for i in product_full_review7:\n",
    "            full_review7.append(i.text.replace('\\n',' ').replace('❤️','').replace('😃', ''))\n",
    "        time.sleep(1)\n",
    "        print(f\"List appended. Lists length: {len(review7)}\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Total reviews: {len(review7)}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that for the list of ratings, we have 60 values from each page. So, we need every 6th element from that list. Using the sliing on the rating7 list to get the desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '5', '5', '5', '4', '5', '5', '5', '5', '5', '5', '5', '5', '5', '4', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '4', '1', '5', '5', '5', '5', '5', '5', '5', '5', '4', '4', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '4', '5', '5', '5', '5', '5', '5', '5', '5', '5', '4', '4', '5', '5', '5', '4', '5', '5', '3', '5', '5', '5', '5', '5', '5', '5', '5', '4', '4', '5', '1', '3', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5']\n"
     ]
    }
   ],
   "source": [
    "rating7 = rating7[::6]\n",
    "print(rating7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have got the desired rating, now making a dataframe of all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money  The iPhone 11 of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.  I’m am v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>The best all rounder iphone. Flipkart is doing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>I upgraded (downgraded?) from my iPhone X sinc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Well , as we all know if its not an Iphone , i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Nice value for money good and best price I pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Just an awesome phone...upgraded from 6s to 11...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratings       Review Summary  \\\n",
       "0        5            Brilliant   \n",
       "1        5     Perfect product!   \n",
       "2        5        Great product   \n",
       "3        5    Worth every penny   \n",
       "4        4          Good choice   \n",
       "..     ...                  ...   \n",
       "95       5  Best in the market!   \n",
       "96       5             Terrific   \n",
       "97       5    Terrific purchase   \n",
       "98       5            Wonderful   \n",
       "99       5            Fabulous!   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money  The iPhone 11 of...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Amazing Powerful and Durable Gadget.  I’m am v...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   So far it’s been an AMAZING experience coming ...  \n",
       "..                                                ...  \n",
       "95  The best all rounder iphone. Flipkart is doing...  \n",
       "96  I upgraded (downgraded?) from my iPhone X sinc...  \n",
       "97  Well , as we all know if its not an Iphone , i...  \n",
       "98  Nice value for money good and best price I pho...  \n",
       "99  Just an awesome phone...upgraded from 6s to 11...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_rating7 = pd.DataFrame()\n",
    "phone_rating7['Ratings'] = rating7\n",
    "phone_rating7['Review Summary'] = review7\n",
    "phone_rating7['Full Review'] = full_review7\n",
    "phone_rating7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: \n",
    "Scrape data for first 100 sneakers you find when you visit flipkart.com and\n",
    "search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "\n",
    "Also note that all the steps required during scraping should be done through code\n",
    "only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver8 = webdriver.Chrome(r\"D:\\Downloads\\IDM Downloads\\chromedriver.exe\")\n",
    "url8 = \"https://www.flipkart.com/\"\n",
    "driver8.get(url8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_button8 = driver8.find_element_by_xpath(\"//button[@class = '_2KpZ6l _2doB4z']\")\n",
    "cross_button8.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting in the search values\n",
    "# searching sneakers\n",
    "search_item8 = driver8.find_element_by_xpath(\"//input[@class = '_3704LK']\")\n",
    "search_item8.send_keys('sneakers')\n",
    "time.sleep(1)\n",
    "\n",
    "#clicking search button\n",
    "search_button8 = driver8.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_button8.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of products from first page: 40\n"
     ]
    }
   ],
   "source": [
    "# Scrapping the brand name from first page\n",
    "brand_name8 = driver8.find_elements_by_xpath(\"//div[@class = '_2WkVRV']\")\n",
    "brand8 = []\n",
    "for i in brand_name8:\n",
    "    brand8.append(i.text)\n",
    "#brand8\n",
    "\n",
    "# Scrapping product description from first page\n",
    "product_desc8 = driver8.find_elements_by_xpath(\"//div[@class = '_2B099V']//a[1]\")\n",
    "description8 = []\n",
    "for i in product_desc8:\n",
    "    description8.append(i.text)\n",
    "#description8\n",
    "\n",
    "# Scrapping price from first page\n",
    "price8 = driver8.find_elements_by_xpath(\"//div[@class = '_30jeq3']\")\n",
    "mrp8 = []\n",
    "for i in price8:\n",
    "    mrp8.append(i.text)\n",
    "#mrp8\n",
    "\n",
    "# SCrapping discount from first page\n",
    "discount8 = driver8.find_elements_by_xpath(\"//div[@class = '_3Ay6Sb']\")\n",
    "disc8 = []\n",
    "for i in discount8:\n",
    "    disc8.append(i.text)\n",
    "#disc8\n",
    "\n",
    "print(f\"Total number of products from first page: {len(brand8)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List appended. Total Products: 80\n"
     ]
    }
   ],
   "source": [
    "if len(brand8) < 100:\n",
    "    next_button8 = driver8.find_element_by_xpath(\"//a[@class = '_1LKTO3']//span\")\n",
    "    next_button8.click()\n",
    "    time.sleep(2)\n",
    "    brand_name8 = driver8.find_elements_by_xpath(\"//div[@class = '_2WkVRV']\")\n",
    "    product_desc8 = driver8.find_elements_by_xpath(\"//div[@class = '_2B099V']//a[1]\")\n",
    "    price8 = driver8.find_elements_by_xpath(\"//div[@class = '_30jeq3']\")\n",
    "    discount8 = driver8.find_elements_by_xpath(\"//div[@class = '_3Ay6Sb']\")   \n",
    "    for i in brand_name8:\n",
    "        brand8.append(i.text)\n",
    "    for i in product_desc8:\n",
    "        description8.append(i.text)\n",
    "    for i in price8:\n",
    "        mrp8.append(i.text)\n",
    "    for i in discount8:\n",
    "        disc8.append(i.text)\n",
    "    print(f\"List appended. Total Products: {len(brand8)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List appended. Total Products: 120\n"
     ]
    }
   ],
   "source": [
    "if len(brand8) < 100:\n",
    "    next_button8 = driver8.find_element_by_xpath(\"//a[@class = '_1LKTO3'][2]\")\n",
    "    next_button8.click()\n",
    "    time.sleep(2)\n",
    "    brand_name8 = driver8.find_elements_by_xpath(\"//div[@class = '_2WkVRV']\")\n",
    "    product_desc8 = driver8.find_elements_by_xpath(\"//div[@class = '_2B099V']//a[1]\")\n",
    "    price8 = driver8.find_elements_by_xpath(\"//div[@class = '_30jeq3']\")\n",
    "    discount8 = driver8.find_elements_by_xpath(\"//div[@class = '_3Ay6Sb']\")   \n",
    "    for i in brand_name8:\n",
    "        brand8.append(i.text)\n",
    "    for i in product_desc8:\n",
    "        description8.append(i.text)\n",
    "    for i in price8:\n",
    "        mrp8.append(i.text)\n",
    "    for i in discount8:\n",
    "        disc8.append(i.text)\n",
    "    print(f\"List appended. Total Products: {len(brand8)}\")\n",
    "else:\n",
    "    print(f\"Total products: {len(brand8)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Description</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Price after discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>Luxury sneaker shoes Sneakers For Men</td>\n",
       "      <td>80% off</td>\n",
       "      <td>₹599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India hub</td>\n",
       "      <td>Canvas casual sneaker shoes Sneakers For Men</td>\n",
       "      <td>71% off</td>\n",
       "      <td>₹569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>62% off</td>\n",
       "      <td>₹379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>60% off</td>\n",
       "      <td>₹398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORICUM</td>\n",
       "      <td>Combo pack of 2 casual sneaker shoes for men S...</td>\n",
       "      <td>62% off</td>\n",
       "      <td>₹377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Xtoon</td>\n",
       "      <td>Casual shoes Sneakers For Men</td>\n",
       "      <td>64% off</td>\n",
       "      <td>₹359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BLACK BOTTOM</td>\n",
       "      <td>Fashion Outdoor Canvas Casual Light Weight Par...</td>\n",
       "      <td>55% off</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>HOTSTYLE</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>40% off</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bersache</td>\n",
       "      <td>Combo Pack of 5 Top Rated, Best Rates Training...</td>\n",
       "      <td>71% off</td>\n",
       "      <td>₹719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>82% off</td>\n",
       "      <td>₹425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Product                                        Description  \\\n",
       "0   luxury fashion              Luxury sneaker shoes Sneakers For Men   \n",
       "1        India hub       Canvas casual sneaker shoes Sneakers For Men   \n",
       "2     Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "3          Numenzo                                   Sneakers For Men   \n",
       "4           ORICUM  Combo pack of 2 casual sneaker shoes for men S...   \n",
       "..             ...                                                ...   \n",
       "95           Xtoon                      Casual shoes Sneakers For Men   \n",
       "96    BLACK BOTTOM  Fashion Outdoor Canvas Casual Light Weight Par...   \n",
       "97        HOTSTYLE                          Sneakers Sneakers For Men   \n",
       "98        Bersache  Combo Pack of 5 Top Rated, Best Rates Training...   \n",
       "99          BRUTON      Combo Pack of 2 Casual Shoes Sneakers For Men   \n",
       "\n",
       "   Discount Price after discount  \n",
       "0   80% off                 ₹599  \n",
       "1   71% off                 ₹569  \n",
       "2   62% off                 ₹379  \n",
       "3   60% off                 ₹398  \n",
       "4   62% off                 ₹377  \n",
       "..      ...                  ...  \n",
       "95  64% off                 ₹359  \n",
       "96  55% off                 ₹449  \n",
       "97  40% off                 ₹299  \n",
       "98  71% off                 ₹719  \n",
       "99  82% off                 ₹425  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products8 = pd.DataFrame()\n",
    "products8['Product'] = brand8[:100]\n",
    "products8['Description'] = description8[:100]\n",
    "products8['Discount'] = disc8[:100]\n",
    "products8['Price after discount'] = mrp8[:100]\n",
    "products8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9: \n",
    "Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”\n",
    "\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of\n",
    "the shoes , Short Shoe description, price of the shoe.\n",
    "\n",
    "Please note that applying the filter and scraping the data , everything should be\n",
    "done through code only and there should not be any manual step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver9 = webdriver.Chrome(r\"D:\\Downloads\\IDM Downloads\\chromedriver.exe\")\n",
    "url = \"https://www.myntra.com/shoes\"\n",
    "driver9.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying colour filter\n",
    "colour_filter9 = driver9.find_element_by_xpath(\"//span[@data-colorhex = 'black']\")\n",
    "colour_filter9.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying price filter\n",
    "price_filter9 = driver9.find_element_by_xpath(\"//*[@id='mountRoot']/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
    "price_filter9.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List appended. Total Products: 50\n"
     ]
    }
   ],
   "source": [
    "# Scrapping the brand of shoe\n",
    "shoe_brand9 = driver9.find_elements_by_xpath(\"//div[@class = 'product-productMetaInfo']//h3[@class = 'product-brand']\")\n",
    "brand9 = []\n",
    "for i in shoe_brand9:\n",
    "    brand9.append(i.text)\n",
    "#brand9\n",
    "\n",
    "# scrapping for product description\n",
    "product_desc9 = driver9.find_elements_by_xpath(\"//div[@class = 'product-productMetaInfo']//h4[@class = 'product-product']\")\n",
    "desc9 = []\n",
    "for i in product_desc9:\n",
    "    desc9.append(i.text)\n",
    "#desc9\n",
    "\n",
    "# Scrapping the price of the shoes\n",
    "shoe_price9 = driver9.find_elements_by_xpath(\"//div[@class = 'product-price']\")\n",
    "price9 = []\n",
    "for i in shoe_price9:\n",
    "    price9.append(i.text[:9].replace('Rs. ', '').replace('R', ''))\n",
    "#price9\n",
    "\n",
    "print(f\"List appended. Total Products: {len(brand9)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to scrap the data for 100 shoes so we move on to next page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List appended. Total Products: 100\n"
     ]
    }
   ],
   "source": [
    "if len(brand9) < 100: # if number of shoes is less than 100\n",
    "    next_button9 = driver9.find_element_by_xpath(\"//a[@rel = 'next']\")\n",
    "    next_button9.click() # clicking the button for next page\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    shoe_brand9 = driver9.find_elements_by_xpath(\"//div[@class = 'product-productMetaInfo']//h3[@class = 'product-brand']\")\n",
    "    product_desc9 = driver9.find_elements_by_xpath(\"//div[@class = 'product-productMetaInfo']//h4[@class = 'product-product']\")\n",
    "    shoe_price9 = driver9.find_elements_by_xpath(\"//div[@class = 'product-price']\")   \n",
    "    \n",
    "    for i in shoe_brand9:\n",
    "        brand9.append(i.text)\n",
    "    \n",
    "    for i in product_desc9:\n",
    "        desc9.append(i.text)\n",
    "    \n",
    "    for i in shoe_price9:\n",
    "        price9.append(i.text[:9].replace('Rs. ', '').replace('R', ''))\n",
    "    \n",
    "    print(f\"List appended. Total Products: {len(brand9)}\")\n",
    "\n",
    "else: # if number of shoes is more than 100\n",
    "    print(f\"Total products: {len(brand9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price after discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men KD13 EP Basketball Shoes</td>\n",
       "      <td>12995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity Running</td>\n",
       "      <td>11621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Unisex Mercedes Running Shoes</td>\n",
       "      <td>7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women PEGASUS 37 Running Shoes</td>\n",
       "      <td>7496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Basketball</td>\n",
       "      <td>12495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>6990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Formal Oxfords</td>\n",
       "      <td>7867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Charged Pursuit 2 Running</td>\n",
       "      <td>6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Ignite Sock Plus Sneakers</td>\n",
       "      <td>6749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men REACT MILER 2 Running</td>\n",
       "      <td>9770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Show Brand                        Description Price after discount\n",
       "0              Nike       Men KD13 EP Basketball Shoes                12995\n",
       "1              Nike         Men React Infinity Running                11621\n",
       "2   PUMA Motorsport      Unisex Mercedes Running Shoes                 7999\n",
       "3              Nike     Women PEGASUS 37 Running Shoes                 7496\n",
       "4              Nike        Men JORDAN DELTA Basketball                12495\n",
       "..              ...                                ...                  ...\n",
       "95            Ruosh  Men Solid Leather Formal Slip-Ons                 6990\n",
       "96             Geox         Men Leather Formal Oxfords                 7867\n",
       "97     UNDER ARMOUR          Charged Pursuit 2 Running                 6999\n",
       "98             Puma      Men Ignite Sock Plus Sneakers                 6749\n",
       "99             Nike          Men REACT MILER 2 Running                 9770\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products9 = pd.DataFrame()\n",
    "products9['Show Brand'] = brand9\n",
    "products9['Description'] = desc9\n",
    "products9['Price after discount'] = price9\n",
    "products9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: \n",
    "Go to webpage https://www.amazon.in/\n",
    "\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”\n",
    "\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes\n",
    "for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver10 = webdriver.Chrome(r\"D:\\Downloads\\IDM Downloads\\chromedriver.exe\")\n",
    "url10 = \"https://www.amazon.in/\"\n",
    "driver10.get(url10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for laptop in the webpage\n",
    "search_item10 = driver10.find_element_by_id(\"twotabsearchtextbox\")\n",
    "search_item10.send_keys('Laptop')\n",
    "\n",
    "# clicking the search button\n",
    "search_button10 = driver10.find_element_by_id(\"nav-search-submit-button\")\n",
    "search_button10.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the filter for i7 processor\n",
    "i7_filer10 = driver10.find_elements_by_xpath(\"//span[@class = 'a-size-base a-color-base']\")\n",
    "for i in i7_filer10:\n",
    "    if i.text == 'Intel Core i7':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping for the laptop names\n",
    "i7_lap_title10 = driver10.find_elements_by_xpath(\"//span[@class = 'a-size-medium a-color-base a-text-normal']\")\n",
    "i7_titles10 = []\n",
    "for i in i7_lap_title10:\n",
    "    i7_titles10.append(i.text)\n",
    "i7_titles10 = i7_titles10[:10]\n",
    "#i7_titles10\n",
    "\n",
    "# Finding the urls for each laptop of i7 processor\n",
    "i7_urls10 = []\n",
    "i7_lap_urls10 = driver10.find_elements_by_xpath(\"//a[@class = 'a-link-normal a-text-normal']\")\n",
    "for i in i7_lap_urls10:\n",
    "    i7_urls10.append(i.get_attribute(\"href\"))\n",
    "i7_urls10 = i7_urls10[:10]\n",
    "#i7_urls10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException # To handle no such element exception\n",
    "\n",
    "# opening every url and scrapping for price and rating of laptop.\n",
    "i7_price10 = []\n",
    "i7_ratings10 = []\n",
    "\n",
    "for i in i7_urls10:\n",
    "    driver10.get(i)\n",
    "    time.sleep(3)\n",
    "    try: # for laptop price\n",
    "        i7_lap_price10 = driver10.find_element_by_xpath(\"//td[@class = 'a-span12']\")\n",
    "        i7_price10.append(i7_lap_price10.text)\n",
    "    except NoSuchElementException:\n",
    "        i7_price10.append('-')\n",
    "    \n",
    "    try: # for laptop rating\n",
    "        i7_lap_rating10 = driver10.find_element_by_xpath(\"//span[@data-hook = 'rating-out-of-text']\")\n",
    "        i7_ratings10.append(i7_lap_rating10.text.replace(' out of 5', ''))\n",
    "    except NoSuchElementException:\n",
    "        i7_ratings10.append('-')\n",
    "\n",
    "        \n",
    "#i7_price10\n",
    "#i7_ratings10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Name</th>\n",
       "      <th>Laptop Price</th>\n",
       "      <th>Laptop Rating</th>\n",
       "      <th>Laptop Processor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>₹ 53,999.00</td>\n",
       "      <td>4.4</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...</td>\n",
       "      <td>₹ 1,35,490.00</td>\n",
       "      <td>4.3</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>₹ 47,050.00</td>\n",
       "      <td>2.9</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>₹ 84,999.00</td>\n",
       "      <td>4.4</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td>₹ 83,990.00</td>\n",
       "      <td>4</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...</td>\n",
       "      <td>₹ 3,43,099.00</td>\n",
       "      <td>4.2</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Renewed) Dell Intel 4th Gen Core i7 4600U 14-...</td>\n",
       "      <td>₹ 39,999.00</td>\n",
       "      <td>-</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CUK VivoBook K571 by ASUS 15 Inch Gaming Lapto...</td>\n",
       "      <td>₹ 1,44,643.00</td>\n",
       "      <td>4.7</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...</td>\n",
       "      <td>₹ 81,990.00</td>\n",
       "      <td>4.4</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo Legion Y540 Intel Core i7 9th Gen 15.6”...</td>\n",
       "      <td>₹ 68,990.00</td>\n",
       "      <td>4</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Laptop Name   Laptop Price  \\\n",
       "0  Mi Notebook Horizon Edition 14 Intel Core i5-1...    ₹ 53,999.00   \n",
       "1  Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...  ₹ 1,35,490.00   \n",
       "2  Life Digital Laptop 15.6-inch (39.62 cms) (Int...    ₹ 47,050.00   \n",
       "3  HP Pavilion (2021) Thin & Light 11th Gen Core ...    ₹ 84,999.00   \n",
       "4  Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...    ₹ 83,990.00   \n",
       "5  Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...  ₹ 3,43,099.00   \n",
       "6  (Renewed) Dell Intel 4th Gen Core i7 4600U 14-...    ₹ 39,999.00   \n",
       "7  CUK VivoBook K571 by ASUS 15 Inch Gaming Lapto...  ₹ 1,44,643.00   \n",
       "8  ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...    ₹ 81,990.00   \n",
       "9  Lenovo Legion Y540 Intel Core i7 9th Gen 15.6”...    ₹ 68,990.00   \n",
       "\n",
       "  Laptop Rating Laptop Processor  \n",
       "0           4.4               i7  \n",
       "1           4.3               i7  \n",
       "2           2.9               i7  \n",
       "3           4.4               i7  \n",
       "4             4               i7  \n",
       "5           4.2               i7  \n",
       "6             -               i7  \n",
       "7           4.7               i7  \n",
       "8           4.4               i7  \n",
       "9             4               i7  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i7_laptops10 = pd.DataFrame()\n",
    "i7_laptops10['Laptop Name'] = i7_titles10\n",
    "i7_laptops10['Laptop Price'] = i7_price10\n",
    "i7_laptops10['Laptop Rating'] = i7_ratings10\n",
    "i7_laptops10['Laptop Processor'] = 'i7'\n",
    "i7_laptops10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, for i9 processors, we scrap the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver10.get(\"https://www.amazon.in/s?k=Laptop&ref=nb_sb_noss_2\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Selecting filter for 19 processor\n",
    "i9_filer10 = driver10.find_elements_by_xpath(\"//span[@class = 'a-size-base a-color-base']\")\n",
    "for i in i9_filer10:\n",
    "    if i.text == 'Intel Core i9':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping for laptop names\n",
    "i9_lap_title10 = driver10.find_elements_by_xpath(\"//span[@class = 'a-size-medium a-color-base a-text-normal']\")\n",
    "i9_titles10 = []\n",
    "for i in i9_lap_title10:\n",
    "    i9_titles10.append(i.text)\n",
    "i9_titles10 = i9_titles10[:10]\n",
    "#i9_titles10\n",
    "\n",
    "# Finding the urls for each 19 processor laptop\n",
    "i9_urls10 = []\n",
    "i9_lap_urls10 = driver10.find_elements_by_xpath(\"//a[@class = 'a-link-normal a-text-normal']\")\n",
    "for i in i9_lap_urls10:\n",
    "    i9_urls10.append(i.get_attribute(\"href\"))\n",
    "i9_urls10 = i9_urls10[:10]\n",
    "#i9_urls10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "i9_price10 = []\n",
    "i9_ratings10 = []\n",
    "\n",
    "# opening every url and scrapping for price and rating of laptop.\n",
    "for i in i9_urls10:\n",
    "    driver10.get(i)\n",
    "    time.sleep(3)\n",
    "    try: # for laptop price\n",
    "        i9_lap_price10 = driver10.find_element_by_xpath(\"//td[@class = 'a-span12']\")\n",
    "        i9_price10.append(i9_lap_price10.text)\n",
    "    except NoSuchElementException:\n",
    "        i9_price10.append('-')\n",
    "        \n",
    "    try: # for laptop rating\n",
    "        i9_lap_rating10 = driver10.find_element_by_xpath(\"//span[@data-hook = 'rating-out-of-text']\")\n",
    "        i9_ratings10.append(i9_lap_rating10.text.replace(' out of 5', ''))\n",
    "    except NoSuchElementException:\n",
    "        i9_ratings10.append('-')\n",
    "        \n",
    "#i9_price10\n",
    "#i9_ratings10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Name</th>\n",
       "      <th>Laptop Price</th>\n",
       "      <th>Laptop Rating</th>\n",
       "      <th>Laptop Processor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS ROG Zephyrus Duo 15, 15.6\" FHD 300Hz/3ms,...</td>\n",
       "      <td>₹ 2,66,990.00</td>\n",
       "      <td>-</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 1...</td>\n",
       "      <td>₹ 4,13,890.00</td>\n",
       "      <td>3.7</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...</td>\n",
       "      <td>₹ 2,99,325.00</td>\n",
       "      <td>3.8</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell XPS 9570 15.6\" (39.62cms) UHD Laptop (8th...</td>\n",
       "      <td>₹ 2,48,790.00</td>\n",
       "      <td>2.4</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...</td>\n",
       "      <td>₹ 2,62,990.00</td>\n",
       "      <td>3.7</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS ZenBook Pro Duo UX581GV-H2041T Intel Core...</td>\n",
       "      <td>₹ 2,79,990.00</td>\n",
       "      <td>3.9</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS ROG Strix Scar 15 (2020), 15.6\" FHD 300Hz...</td>\n",
       "      <td>₹ 2,15,990.00</td>\n",
       "      <td>4.2</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS ROG Strix Scar 17 (2020), 17.3\" FHD 300Hz...</td>\n",
       "      <td>₹ 2,77,639.00</td>\n",
       "      <td>4.8</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) Dell XPS 9570 Laptop|i9-8950HK|32GB ...</td>\n",
       "      <td>₹ 1,89,900.00</td>\n",
       "      <td>-</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Apple MacBook Pro (16-inch, 16GB RAM, 1TB Stor...</td>\n",
       "      <td>₹ 2,15,990.00</td>\n",
       "      <td>4.2</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Laptop Name   Laptop Price  \\\n",
       "0  ASUS ROG Zephyrus Duo 15, 15.6\" FHD 300Hz/3ms,...  ₹ 2,66,990.00   \n",
       "1  ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 1...  ₹ 4,13,890.00   \n",
       "2  ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...  ₹ 2,99,325.00   \n",
       "3  Dell XPS 9570 15.6\" (39.62cms) UHD Laptop (8th...  ₹ 2,48,790.00   \n",
       "4  Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...  ₹ 2,62,990.00   \n",
       "5  ASUS ZenBook Pro Duo UX581GV-H2041T Intel Core...  ₹ 2,79,990.00   \n",
       "6  ASUS ROG Strix Scar 15 (2020), 15.6\" FHD 300Hz...  ₹ 2,15,990.00   \n",
       "7  ASUS ROG Strix Scar 17 (2020), 17.3\" FHD 300Hz...  ₹ 2,77,639.00   \n",
       "8  (Renewed) Dell XPS 9570 Laptop|i9-8950HK|32GB ...  ₹ 1,89,900.00   \n",
       "9  Apple MacBook Pro (16-inch, 16GB RAM, 1TB Stor...  ₹ 2,15,990.00   \n",
       "\n",
       "  Laptop Rating Laptop Processor  \n",
       "0             -               i9  \n",
       "1           3.7               i9  \n",
       "2           3.8               i9  \n",
       "3           2.4               i9  \n",
       "4           3.7               i9  \n",
       "5           3.9               i9  \n",
       "6           4.2               i9  \n",
       "7           4.8               i9  \n",
       "8             -               i9  \n",
       "9           4.2               i9  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i9_laptops10 = pd.DataFrame()\n",
    "i9_laptops10['Laptop Name'] = i9_titles10\n",
    "i9_laptops10['Laptop Price'] = i9_price10\n",
    "i9_laptops10['Laptop Rating'] = i9_ratings10\n",
    "i9_laptops10['Laptop Processor'] = 'i9'\n",
    "i9_laptops10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Name</th>\n",
       "      <th>Laptop Price</th>\n",
       "      <th>Laptop Rating</th>\n",
       "      <th>Laptop Processor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>₹ 53,999.00</td>\n",
       "      <td>4.4</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...</td>\n",
       "      <td>₹ 1,35,490.00</td>\n",
       "      <td>4.3</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>₹ 47,050.00</td>\n",
       "      <td>2.9</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>₹ 84,999.00</td>\n",
       "      <td>4.4</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td>₹ 83,990.00</td>\n",
       "      <td>4</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...</td>\n",
       "      <td>₹ 3,43,099.00</td>\n",
       "      <td>4.2</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Renewed) Dell Intel 4th Gen Core i7 4600U 14-...</td>\n",
       "      <td>₹ 39,999.00</td>\n",
       "      <td>-</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CUK VivoBook K571 by ASUS 15 Inch Gaming Lapto...</td>\n",
       "      <td>₹ 1,44,643.00</td>\n",
       "      <td>4.7</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...</td>\n",
       "      <td>₹ 81,990.00</td>\n",
       "      <td>4.4</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo Legion Y540 Intel Core i7 9th Gen 15.6”...</td>\n",
       "      <td>₹ 68,990.00</td>\n",
       "      <td>4</td>\n",
       "      <td>i7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ASUS ROG Zephyrus Duo 15, 15.6\" FHD 300Hz/3ms,...</td>\n",
       "      <td>₹ 2,66,990.00</td>\n",
       "      <td>-</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 1...</td>\n",
       "      <td>₹ 4,13,890.00</td>\n",
       "      <td>3.7</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...</td>\n",
       "      <td>₹ 2,99,325.00</td>\n",
       "      <td>3.8</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dell XPS 9570 15.6\" (39.62cms) UHD Laptop (8th...</td>\n",
       "      <td>₹ 2,48,790.00</td>\n",
       "      <td>2.4</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...</td>\n",
       "      <td>₹ 2,62,990.00</td>\n",
       "      <td>3.7</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ASUS ZenBook Pro Duo UX581GV-H2041T Intel Core...</td>\n",
       "      <td>₹ 2,79,990.00</td>\n",
       "      <td>3.9</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ASUS ROG Strix Scar 15 (2020), 15.6\" FHD 300Hz...</td>\n",
       "      <td>₹ 2,15,990.00</td>\n",
       "      <td>4.2</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ASUS ROG Strix Scar 17 (2020), 17.3\" FHD 300Hz...</td>\n",
       "      <td>₹ 2,77,639.00</td>\n",
       "      <td>4.8</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(Renewed) Dell XPS 9570 Laptop|i9-8950HK|32GB ...</td>\n",
       "      <td>₹ 1,89,900.00</td>\n",
       "      <td>-</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Apple MacBook Pro (16-inch, 16GB RAM, 1TB Stor...</td>\n",
       "      <td>₹ 2,15,990.00</td>\n",
       "      <td>4.2</td>\n",
       "      <td>i9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Laptop Name   Laptop Price  \\\n",
       "0   Mi Notebook Horizon Edition 14 Intel Core i5-1...    ₹ 53,999.00   \n",
       "1   Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...  ₹ 1,35,490.00   \n",
       "2   Life Digital Laptop 15.6-inch (39.62 cms) (Int...    ₹ 47,050.00   \n",
       "3   HP Pavilion (2021) Thin & Light 11th Gen Core ...    ₹ 84,999.00   \n",
       "4   Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...    ₹ 83,990.00   \n",
       "5   Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...  ₹ 3,43,099.00   \n",
       "6   (Renewed) Dell Intel 4th Gen Core i7 4600U 14-...    ₹ 39,999.00   \n",
       "7   CUK VivoBook K571 by ASUS 15 Inch Gaming Lapto...  ₹ 1,44,643.00   \n",
       "8   ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...    ₹ 81,990.00   \n",
       "9   Lenovo Legion Y540 Intel Core i7 9th Gen 15.6”...    ₹ 68,990.00   \n",
       "10  ASUS ROG Zephyrus Duo 15, 15.6\" FHD 300Hz/3ms,...  ₹ 2,66,990.00   \n",
       "11  ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 1...  ₹ 4,13,890.00   \n",
       "12  ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...  ₹ 2,99,325.00   \n",
       "13  Dell XPS 9570 15.6\" (39.62cms) UHD Laptop (8th...  ₹ 2,48,790.00   \n",
       "14  Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...  ₹ 2,62,990.00   \n",
       "15  ASUS ZenBook Pro Duo UX581GV-H2041T Intel Core...  ₹ 2,79,990.00   \n",
       "16  ASUS ROG Strix Scar 15 (2020), 15.6\" FHD 300Hz...  ₹ 2,15,990.00   \n",
       "17  ASUS ROG Strix Scar 17 (2020), 17.3\" FHD 300Hz...  ₹ 2,77,639.00   \n",
       "18  (Renewed) Dell XPS 9570 Laptop|i9-8950HK|32GB ...  ₹ 1,89,900.00   \n",
       "19  Apple MacBook Pro (16-inch, 16GB RAM, 1TB Stor...  ₹ 2,15,990.00   \n",
       "\n",
       "   Laptop Rating Laptop Processor  \n",
       "0            4.4               i7  \n",
       "1            4.3               i7  \n",
       "2            2.9               i7  \n",
       "3            4.4               i7  \n",
       "4              4               i7  \n",
       "5            4.2               i7  \n",
       "6              -               i7  \n",
       "7            4.7               i7  \n",
       "8            4.4               i7  \n",
       "9              4               i7  \n",
       "10             -               i9  \n",
       "11           3.7               i9  \n",
       "12           3.8               i9  \n",
       "13           2.4               i9  \n",
       "14           3.7               i9  \n",
       "15           3.9               i9  \n",
       "16           4.2               i9  \n",
       "17           4.8               i9  \n",
       "18             -               i9  \n",
       "19           4.2               i9  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops10 = pd.concat([i7_laptops10, i9_laptops10], ignore_index = True)\n",
    "laptops10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
